#!/usr/bin/env python3
"""
collage.py
==========

Create a multi-track “collage” out of the pre-sliced speech *bits*
generated by **preprocess.py**.

Steps
-----
1.  Read every WAV file in ``bits/``.
2.  Build *N* stereo tracks (default 10) aligned to a **beat-grid**  
    – beat length = ``60_000 / BPM`` ms.
3.  For each grid beat and for each track decide (by **pattern symbol**)
    whether to spawn a bit:
       *   energy symbols (L M H) → soft / medium / high probability
       *   S = silence; C = crescendo (+6 dB ramp); D = diminuendo.
       *   lower-case (l m h) == solo track 0.
4.  Optionally add *style* FX: pan, reverb, echo, stretch, gain
    (`--apply-styles`).
5.  Write individual ``track<i>.wav`` plus combined ``master.wav`` into
    a timestamped folder under ``out/``.

CLI
---
::

    python collage.py                    # default mix, no FX
    python collage.py --apply-styles
    python collage.py --pattern "SSLChhDD" --bpm 100 --csv
    python collage.py --help             # detailed pattern guide

The script never overwrites previous mixes; each run creates a fresh
sub-folder like ``out/collage_25.06.16_08.44_s/`` ( *s* = styles on,
*ns* = no styles ).

Dependencies
------------
* **pydub** + FFmpeg (read/write WAV, pan, FX)
* **numpy / librosa** (stretch)
* **noisereduce** (optional ‘auto-fix’ denoise)
* see ``requirements.txt`` for the full list.

All heavy DSP is pre-done in *preprocess*; this file only overlays and
adds light creative FX, so it runs in seconds even on large bit pools.
"""
# ── imports ──────────────────────────────────────────────────────────────
import os
import sys
import csv
import random
import datetime
import numpy as np
import librosa
import noisereduce as nr
from pydub import AudioSegment, effects
from pydub.generators import Sine

# ── user-tweakable constants ─────────────────────────────────────────────
BITS_DIR = "bits"  # where preprocess.py writes the snippets
TRACK_COUNT = 10  # number of parallel tracks
TARGET_MS = 30_000  # total collage length (30 s default)

# silence between bit spawns  (used when pattern == energy symbols)
MIN_SIL_MS, MAX_SIL_MS = 100, 3_000

# style FX (only if --apply-styles given)
FADE_MS = 100
REVERB_DELAYS = [120, 150, 170]  # ms taps
REVERB_DECAY = 0.10
ECHO_CHANCE, ECHO_DELAY_MS = 0.3, 500
STRETCH_PROB, STRETCH_RANGE = 0.3, (0.8, 1.2)
PAN_RANGE, GAIN_RANGE_DB = (-1, 1), (-3, +3)

# hum bed (disabled by default; was formerly used)
HUM_FREQ_HZ, HUM_GAIN_DB = 80, -10

# pattern → spawn-probability table
PROB_TABLE = {
    "S": 0.01,
    "L": 0.3,
    "M": 0.6,
    "H": 0.9,
    "l": 0.3,
    "m": 0.6,
    "h": 0.9,
    "C": None,
    "D": None,  # probability unchanged, only gain ramps
}

# ── CLI parsing -----------------------------------------------------------
if "--help" in sys.argv:
    print(__doc__)
    sys.exit(0)

apply_styles = "--apply-styles" in sys.argv
write_csv = "--csv" in sys.argv

# pattern string (default “M” == medium energy)
pattern = next(
    (sys.argv[i + 1] for i, v in enumerate(sys.argv[:-1]) if v == "--pattern"), "M"
)
bpm = int(
    next((sys.argv[i + 1] for i, v in enumerate(sys.argv[:-1]) if v == "--bpm"), 120)
)

# ── output folder ---------------------------------------------------------
stamp = datetime.datetime.now().strftime("collage_%y.%m.%d_%H.%M_")
stamp += "s" if apply_styles else "ns"
OUT_DIR = os.path.join("out", stamp)
os.makedirs(OUT_DIR, exist_ok=True)
print(f"⇒ Output folder: {OUT_DIR}")

# write pattern for reference
with open(os.path.join(OUT_DIR, "pattern.txt"), "w") as f:
    f.write(pattern + "\n")

# ── load bits -------------------------------------------------------------
bits = [
    (bf, AudioSegment.from_wav(os.path.join(BITS_DIR, bf)))
    for bf in os.listdir(BITS_DIR)
    if bf.lower().endswith(".wav")
]
print(f"{len(bits)} bits loaded\n")


# ── helper FX functions ---------------------------------------------------
def apply_reverb(seg: AudioSegment) -> AudioSegment:
    """Very light 3-tap delay reverb."""
    out = seg
    for i, d in enumerate(REVERB_DELAYS, 1):
        out = out.overlay(seg - (i * (1 - REVERB_DECAY) * 10), position=d)
    return out


def apply_echo(seg: AudioSegment) -> AudioSegment:
    """Single slap-back echo at −10 dB."""
    return seg.overlay(seg - 10, position=ECHO_DELAY_MS)


def maybe_stretch(seg: AudioSegment) -> AudioSegment:
    """Random time-stretch  0.8× ↔ 1.2×  (pitch-preserving)."""
    if random.random() > STRETCH_PROB:
        return seg
    y = np.array(seg.get_array_of_samples()).astype(np.float32) / 32768
    y2 = librosa.effects.time_stretch(y=y, rate=random.uniform(*STRETCH_RANGE))
    data = (y2 * 32767).astype(np.int16).tobytes()
    return AudioSegment(data, frame_rate=seg.frame_rate, sample_width=2, channels=1)


def auto_fix(seg: AudioSegment) -> AudioSegment:
    """
    Cheap & cheerful doctor:
    * very loud broadband noise  → denoise (noisereduce)
    * dull 80s tape              → add air via gentle EQ
    * music-heavy                → light 2:1 compression (+2 dB)
    """
    y = np.array(seg.get_array_of_samples()).astype(np.float32) / 32768
    sr = seg.frame_rate
    rms_db = 20 * np.log10(np.sqrt(np.mean(y**2)) + 1e-9)
    centroid = float(np.mean(librosa.feature.spectral_centroid(y=y, sr=sr)))

    out = seg
    if rms_db > -30:  # loud hiss floor
        out = AudioSegment(
            (nr.reduce_noise(y=y, sr=sr, prop_decrease=0.8) * 32767)
            .astype(np.int16)
            .tobytes(),
            frame_rate=sr,
            sample_width=2,
            channels=1,
        )

    elif centroid < 1_000:  # very dull tape
        out = out.high_pass_filter(40).low_pass_filter(16_000).apply_gain(+2)

    # detect “music-heavy” by hi-vs-lo spectrum
    spec = np.abs(np.fft.rfft(y))
    if spec[int(len(spec) * 0.7) :].mean() > spec[: int(len(spec) * 0.1)].mean() * 2:
        out = effects.compress_dynamic_range(
            out, threshold=-18, ratio=2, attack=10, release=250
        ).apply_gain(+2)
    return out


# ── create empty stereo tracks -------------------------------------------
blank = AudioSegment.silent(duration=TARGET_MS).set_channels(2)
tracks = [blank[:] for _ in range(TRACK_COUNT)]

# ── rhythm parameters -----------------------------------------------------
beat_ms = 60_000 / bpm
sec_len = TARGET_MS // len(pattern)
metadata = []  # for optional CSV
gain = 0.0  # running track gain (dB)

print("Building tracks …")
for sec_idx, sym in enumerate(pattern):
    sec_start = sec_idx * sec_len
    sec_end = min(TARGET_MS, (sec_idx + 1) * sec_len)

    prob = PROB_TABLE.get(sym, 0.5)
    active = [True] * TRACK_COUNT
    if sym in "lmh":  # solo track 0
        active = [t == 0 for t in range(TRACK_COUNT)]

    # gain ramps
    target_gain = gain
    if sym == "C":
        target_gain = +6.0
    if sym == "D":
        target_gain = -6.0

    for t in range(TRACK_COUNT):
        cursor = sec_start
        while cursor < sec_end:
            # random gap before next spawn
            cursor += random.randint(MIN_SIL_MS, MAX_SIL_MS)
            if cursor >= sec_end:
                break
            if not active[t] or random.random() > (prob or 0.5):
                continue

            bf, seg = random.choice(bits)
            seg = auto_fix(seg)
            seg = effects.normalize(seg, headroom=6.0)

            if apply_styles:
                seg = maybe_stretch(seg).fade_in(FADE_MS).fade_out(FADE_MS)
                if random.random() < ECHO_CHANCE:
                    seg = apply_echo(seg)
                seg = apply_reverb(seg)
                seg = seg.pan(random.uniform(*PAN_RANGE))
                seg = seg.apply_gain(random.uniform(*GAIN_RANGE_DB) + gain)
            else:
                seg = seg.apply_gain(gain)

            tracks[t] = tracks[t].overlay(seg, position=int(cursor))
            metadata.append(
                {"track": t, "bit": bf, "start_ms": int(cursor), "dur_ms": len(seg)}
            )
            cursor += len(seg)

    gain = target_gain  # update for next section

# ── save individual tracks -----------------------------------------------
for i, tr in enumerate(tracks):
    p = os.path.join(OUT_DIR, f"track{i}.wav")
    tr.export(p, format="wav")
    print(f"  track {i} → {p}")

# ── mix master (simple overlay) ------------------------------------------
master = tracks[0]
for tr in tracks[1:]:
    master = master.overlay(tr)

# auto-trim to −1 dBFS headroom
peak_db = master.max_dBFS
if peak_db > -1.0:
    master = master.apply_gain(-1.0 - peak_db)
    print(f"  master auto-gained { -1.0 - peak_db:+.1f} dB")

master_path = os.path.join(OUT_DIR, "master.wav")
master.export(master_path, format="wav")
print(f"\n✔ master → {master_path}")

# optional CSV debug log
if write_csv and metadata:
    with open(os.path.join(OUT_DIR, "collage_debug.csv"), "w", newline="") as f:
        w = csv.DictWriter(f, fieldnames=metadata[0].keys())
        w.writeheader()
        w.writerows(metadata)
    print("✔ CSV    → collage_debug.csv")

print("\nDone.")
